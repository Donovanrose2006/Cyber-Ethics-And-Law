# Policy Snippet (Final)
Our AI phishing detector uses AI to scan emails sent to any email address within the organization to minimize the amount of users falling victim to phishing emails. Our team only uses this to scan emails from non-organizational email addresses. When the AI flags the alert from a specific email address multiple times, a human security analyst will analyze the emails sent and decide if any action is necessary. When analyzing, we redact any sensitive information, such as names and email addresses the suspicious email was sent to. If expecting an email that never arrives, contact the IT security team, and we can look through the logs and restore discarded emails within 21 days of the original send date. We retrain the AI quarterly, and intend to improve the AI detection each time.
# Control and Metrics
3 controls of an AI phishing filter would be transparency (every alert showing a reason code), HIL with humans that can override decisions, and metrics that show if retraining is necessary or if everything is going well. 2 metrics would be the TP/TN and FP/FN statistics and the time it takes for the AI to determine what is a phishing email and what is normal.
# Justification
These risks are worth it for the benefits they provide. The AI usage gives us more freedom to take care of heavier tasks and gives current security analysts more time to work on different issues.
# Evidence Links
https://www.forbes.com/councils/forbestechcouncil/2025/09/26/smarter-happier-safer-socs-how-ai-transforms-cybersecurity-defense/
# Reflection 
I'd like to be able to go into more depth for the AI usage, but as usual, it's difficult with the open ended-ness of the prompt.
